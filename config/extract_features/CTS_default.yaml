mode: randomsample

trainer:
  max_epochs: 1
  accelerator: gpu
  devices: 
    - 0
    
model:
  image_size: &imagesize 224

  lr: 0.001
  beta1: 0.9
  beta2: 0.999

  net:
    model_name: resnet34
    # model_name: vit_small_patch16_224_dino

    pretrained: True
    num_classes: -1
    

  dino:
    # hidden_layer: norm
    hidden_layer: fc
    projection_hidden_size: 128      # projector network hidden dimension
    student_temp: 0.9                # student temperature
    num_classes_K: 4096             # output logits dimensions (referenced as K in paper)
    teacher_temp: 0.04               # teacher temperature, needs to be annealed from 0.04 to 0.07 over 30 epochs
    local_upper_crop_scale: 0.4      # upper bound for local crop - 0.4 was recommended in the paper
    global_lower_crop_scale: 0.5     # lower bound for global crop - 0.5 was recommended in the paper
    moving_average_decay: 0.9        # moving average of encoder - paper showed anywhere from 0.9 to 0.999 was ok
    center_moving_average_decay: 0.9 # moving average of teacher centers - paper showed anywhere from 0.9 to 0.999 was ok
    projection_layers: 3             # number of layers in projection network

data_module:
  image_size: *imagesize
  batch_size: 128
  num_workers: 4
  split_random_state: 0
  filemanager:
    #root: ./dataset/jpg_raw/nikon/
    #index_xlsx: ./dataset/jpg_raw/index.xlsx
    root: ./dataset/CTS_sample_100/
    index_xlsx: ./dataset/nikon/index.xlsx
    exts:
      - jpg
      - jpeg
    pairs:
      - name: 'ng'
        label: 0
      - name: 'ca'
        label: 1
    
  file_spoiler:
    types:
      - cell
    classes:
      - ng
      - ca
    labels:
      [0,1]
    magnifications:
      - 200x