common: &common
  image_size: 224

run_dino_id:
run_dino:
  <<: *common
  max_epochs: 100
  accelerator: gpu
  gpus: 
    - 0
  batch_size: 64
  num_workers: 20
  lr: 0.001
  beta1: 0.9
  beta2: 0.999

  net:
    model_name: vit_small_patch16_224_dino
    pretrained: True
    num_classes: -1

  dino:
    hidden_layer: norm
    projection_hidden_size: 128      # projector network hidden dimension
    student_temp: 0.9                # student temperature
    num_classes_K: 4096             # output logits dimensions (referenced as K in paper)
    teacher_temp: 0.04               # teacher temperature, needs to be annealed from 0.04 to 0.07 over 30 epochs
    local_upper_crop_scale: 0.4      # upper bound for local crop - 0.4 was recommended in the paper
    global_lower_crop_scale: 0.5     # lower bound for global crop - 0.5 was recommended in the paper
    moving_average_decay: 0.9        # moving average of encoder - paper showed anywhere from 0.9 to 0.999 was ok
    center_moving_average_decay: 0.9 # moving average of teacher centers - paper showed anywhere from 0.9 to 0.999 was ok
    projection_layers: 3             # number of layers in projection network

  filemanager:
    root: ./dataset/jpg_raw/nikon/
    index_xlsx: ./dataset/jpg_raw/index.xlsx
    exts:
      - jpg
      - jpeg

  file_spoiler:
    types: 
      - cell
    classes:
      - ca
      - ng
      - nr1
      - nr2
    magnifications:
      - 040x

preprocess_id:
preprocess:
  mode: pca_umap
  reducer:
    pca_args:
      n_components: 4
      random_state: 0
    umap_args:
      n_components: 2
      random_state: 0
    should_normalize: True

classify_id:
classify:
  # n_clusters: 16
  kmeans_args:
    n_clusters: 16
    random_state: 0


dclike_id:
dclike:
  <<: *common
  max_epochs: 100
  accelerator: gpu
  gpus: 
    - 0
  batch_size: 256
  num_workers: 4
  lr: 0.001
  beta1: 0.9
  beta2: 0.999